{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=  0 x =  -4.0 y =  4.0 f= 14464.0\n",
      "iter=  1 x =  2.1725760772337908 y =  4.714631616431764 f= 3.3424541086780915\n",
      "iter=  2 x =  2.1721931982225215 y =  4.715017438482135 f= 3.342037687355509\n",
      "iter=  3 x =  2.325047166058232 y =  5.364249825884022 f= 2.9784772265710013\n",
      "iter=  4 x =  2.4990079422709788 y =  6.186607994894793 f= 2.5944152077580758\n",
      "iter=  5 x =  2.6531597686283375 y =  6.971722092137102 f= 2.270071716379317\n",
      "iter=  6 x =  2.8048362211014966 y =  7.795310079561646 f= 1.9438851400037547\n",
      "iter=  7 x =  2.9343941868994357 y =  8.542304683974592 f= 1.602887057153557\n",
      "iter=  8 x =  3.1555845738904793 y =  9.90155935683354 f= 1.0283718401852633\n",
      "iter=  9 x =  3.3968744631776913 y =  11.503137345817645 f= 0.4906301105389965\n",
      "iter=  10 x =  4.068029302556662 y =  16.54917926463927 f= 0.00463802591694589\n",
      "iter=  11 x =  4.0680591013571155 y =  16.549187717870076 f= 0.004632727950551997\n",
      "iter=  12 x =  4.068054229636659 y =  16.549035837405103 f= 0.004631464477302643\n",
      "iter=  13 x =  3.995425073455882 y =  15.964157514252012 f= 7.509906007041232e-05\n",
      "iter=  14 x =  3.9947395758640645 y =  15.957920824368518 f= 2.7727073944609398e-05\n",
      "iter=  15 x =  3.9947372237677277 y =  15.95791789853713 f= 2.7702572080295828e-05\n",
      "iter=  16 x =  3.9947370446189154 y =  15.957918023533574 f= 2.770233798694821e-05\n",
      "iter=  17 x =  3.994737369469165 y =  15.957928758975347 f= 2.769572444599432e-05\n",
      "iter=  18 x =  3.995297386125336 y =  15.962564725641395 f= 2.4788523712347212e-05\n",
      "iter=  19 x =  4.000183705621647 y =  16.001515956633995 f= 2.479122791508527e-07\n",
      "iter=  20 x =  4.0002297752162335 y =  16.001839105198023 f= 5.286901419604143e-08\n",
      "iter=  21 x =  4.000229848886379 y =  16.00183914195458 f= 5.283939293875057e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rosenbrock(X,funcParams, doGradient):\n",
    "  \"\"\"\n",
    "  Compute the Rosenbrock function and optionally its gradient.\n",
    "  \n",
    "  The Rosenbrock function is defined as:\n",
    "      f(x, y) = (a - x)^2 + b * (y - x^2)^2\n",
    "  where 'a' and 'b' are parameters that control the shape of the function.\n",
    "\n",
    "  Parameters:\n",
    "      X (array-like): A 2-element array representing the point [x, y] in 2D space\n",
    "                      where the function and gradient are evaluated.\n",
    "      funcParams (array-like): A 2-element array containing the parameters [a, b]\n",
    "                                for the Rosenbrock function.\n",
    "      doGradient (bool): If True, the function also returns the gradient vector.\n",
    "                          If False, only the function value is returned.\n",
    "\n",
    "  Returns:\n",
    "      f (float): The value of the Rosenbrock function at the given point [x, y].\n",
    "      gradf (numpy.ndarray or None): The gradient vector [df/dx, df/dy] if doGradient is True.\n",
    "                                      If doGradient is False, returns None for the gradient.\n",
    "  \"\"\"\n",
    "  x = X[0]\n",
    "  y = X[1]\n",
    "  \n",
    "  a = funcParams[0]\n",
    "  b = funcParams[1]\n",
    "  \n",
    "  x2 = x*x\n",
    "  \n",
    "  t1 = a-x\n",
    "  t2 = y-x2\n",
    "  \n",
    "  f = t1**2 + b*t2**2\n",
    "  \n",
    "  if doGradient:\n",
    "    dfdx = - 2*t1 - 4*b*x*t2\n",
    "    dfdy = 2*b*t2\n",
    "  \n",
    "    gradf = np.array([dfdx,dfdy])\n",
    "  \n",
    "    return f, gradf\n",
    "  else:\n",
    "    return f, None\n",
    "\n",
    "def line_search(X, S, func, funcParams, maxIter, tol):\n",
    "    \"\"\"\n",
    "    Perform a golden section line search to find the optimal alpha that minimizes\n",
    "    the function F(X + alpha * S).\n",
    "    \n",
    "    Parameters:\n",
    "        X (array-like): Current point in the space.\n",
    "        S (array-like): Search direction.\n",
    "        tol (float): Tolerance for stopping criterion.\n",
    "        max_iter (int): Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        alpha_star (float): The optimal step size.\n",
    "    \"\"\"\n",
    "    # Golden ratio\n",
    "    phi = (1 + np.sqrt(5)) / 2\n",
    "    inv_phi = 1 / phi\n",
    "\n",
    "    # Initial interval [a, b]\n",
    "    a = 0\n",
    "    b = 1\n",
    "    # Evaluate points within the interval\n",
    "    alpha1 = b - inv_phi * (b - a)\n",
    "    alpha2 = a + inv_phi * (b - a)\n",
    "\n",
    "    # Compute objective function values at the points\n",
    "    f1 = func(X + alpha1 * S, funcParams, False)\n",
    "    f2 = func(X + alpha2 * S, funcParams, False)\n",
    "\n",
    "    # Iteratively narrow the search interval\n",
    "    for _ in range(maxIter):\n",
    "        if abs(b - a) < tol:\n",
    "            break\n",
    "\n",
    "        # Compare function values and update the interval\n",
    "        if f1 < f2:\n",
    "            b = alpha2\n",
    "            alpha2 = alpha1\n",
    "            f2 = f1\n",
    "            alpha1 = b - inv_phi * (b - a)\n",
    "            f1 = func(X + alpha1 * S, funcParams, False)\n",
    "        else:\n",
    "            a = alpha1\n",
    "            alpha1 = alpha2\n",
    "            f1 = f2\n",
    "            alpha2 = a + inv_phi * (b - a)\n",
    "            f2 = func(X + alpha2 * S, funcParams, False)\n",
    "\n",
    "    # Optimal step size is the midpoint of the final interval\n",
    "    alpha_star = (a + b) / 2\n",
    "    return alpha_star\n",
    "\n",
    "\n",
    "def opt(X0,func, funcParams, maxLineSearchIters, lineSearchTol, absTol, relTol):\n",
    "  # Step 1: Initialize\n",
    "  X = X0\n",
    "  \n",
    "  iters = 0\n",
    "  \n",
    "  f, gradf = func(X, funcParams, True)\n",
    "  a = np.dot(gradf, gradf)\n",
    "  print(\"iter= \", iters, \"x = \", X[0], \"y = \", X[1], \"f=\", f)\n",
    "\n",
    "  while True:\n",
    "\n",
    "    # If first time or if Fletcher-Reeves fails, then just select steepest decent\n",
    "    S = -gradf\n",
    "    \n",
    "    # Step 2: Line search to find optimal alpha\n",
    "    alpha_star = line_search(X, S, func, funcParams, maxLineSearchIters, lineSearchTol)\n",
    "\n",
    "    # Step 3: Check if alpha_star equals zero\n",
    "    if np.abs(alpha_star)<=1e-10:\n",
    "      print(\"Alpha is zero, algorithm exits.\")\n",
    "      break\n",
    "    \n",
    "    # Step 4: Update X\n",
    "    X = X + alpha_star * S\n",
    "    \n",
    "    # Step 5: compute function and gradient at new X\n",
    "    f, gradf = func(X, funcParams, True)\n",
    "\n",
    "    while True:\n",
    "      \n",
    "      # Compute Fletcher-Reeves conjugate direction Update:\n",
    "      b = np.dot(gradf,gradf)\n",
    "      beta = b/a\n",
    "      S = -gradf + beta*S\n",
    "      a = b\n",
    "      \n",
    "      # if slope is greater than 0, break\n",
    "      if np.dot(S,gradf)>=0:\n",
    "        break\n",
    "      \n",
    "      \n",
    "      alpha_star = line_search(X, S, func, funcParams, maxLineSearchIters, lineSearchTol)\n",
    "      \n",
    "      X_new = X + alpha_star * S\n",
    "      f_new, gradf_new = func(X_new, funcParams, True)\n",
    "\n",
    "      if np.abs(f_new - f)/np.abs(f)<= relTol or np.abs(f_new - f)<=absTol:\n",
    "        return X_new, f_new\n",
    "      else:\n",
    "        X = X_new\n",
    "        f = f_new\n",
    "        gradf = gradf_new\n",
    "        iters = iters + 1\n",
    "        print(\"iter= \", iters, \"x = \", X[0], \"y = \", X[1], \"f=\", f)\n",
    "    iters = iters + 1\n",
    "    \n",
    "  return X, f\n",
    "\n",
    "\n",
    "# Test Case\n",
    "def testCGWithRosenBrock():\n",
    "  X0 = np.array([-4.0,4.0])\n",
    "\n",
    "  a = 4\n",
    "  b = 100\n",
    "  rosenbrockFuncParams = np.array([a,b])\n",
    "  maxLineSearchIters = 100\n",
    "  lineSearchTol = 1e-4\n",
    "  relTol = 1e-12\n",
    "  absTol = 1e-16\n",
    "\n",
    "  opt(X0,rosenbrock, rosenbrockFuncParams, maxLineSearchIters, lineSearchTol, absTol, relTol)\n",
    "\n",
    "\n",
    "# Run test cases\n",
    "testCGWithRosenBrock()\n",
    "      \n",
    "\n",
    "      \n",
    "      \n",
    "\n",
    "  \n",
    "  \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
